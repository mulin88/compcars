{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Before training,the mean must be substract\n",
    "def jbtrain(trainingset,label):\n",
    "    # the total num of image\n",
    "    m=len(label)\n",
    "    \n",
    "    # the dim of features\n",
    "    n=trainingset.shape[1]\n",
    "#     label = label.reshape(1, len(label))   \n",
    "    label = np.squeeze(np.asarray(label))\n",
    "    \n",
    "    classes, labels = np.unique(label, return_inverse=True)\n",
    "    print('classes.size: {}'.format(len(classes)))\n",
    "    print('index: {}'.format(labels))\n",
    "    \n",
    "    print('feature shape {}, dim of feature {}, label shape {}, unique labels {}'.format(trainingset.shape, n, label.shape, len(classes)))\n",
    "    \n",
    "    # filter the complicate label,for count the total people num\n",
    "#     classes,labels=np.unique(label,return_inverse=True)\n",
    "    # the total people num\n",
    "    nc=len(classes)\n",
    "  \n",
    "    Sw=np.zeros([n,n])\n",
    "    # save each people items\n",
    "    cur={}\n",
    "    withinCount=0\n",
    "    # record the count of each people\n",
    "    numberBuff=np.zeros(1000)\n",
    "    \n",
    "    for i in range(nc):\n",
    "        \n",
    "        # get the item of i\n",
    "        cur[i]=trainingset[labels==i]     ## ！！！\n",
    "        if cur[i].shape[0]>1:\n",
    "            withinCount=withinCount+cur[i].shape[0]\n",
    "        if numberBuff[cur[i].shape[0]] == 0 :\n",
    "            numberBuff[cur[i].shape[0]] = 1\n",
    "#         print('current label: {}/{}'.format(i, len(cur[i])))\n",
    "    u=np.zeros([n,nc])\n",
    "    ep=np.zeros([n,withinCount])\n",
    "    nowp=0\n",
    "    for i in range(nc):\n",
    "        # the mean of cur[i]\n",
    "        u[:,i]=np.mean(cur[i],0)\n",
    "        b=u[:,i].reshape(n,1)\n",
    "        if cur[i].shape[0]>1:\n",
    "            ep[:,nowp:nowp+cur[i].shape[0]]=cur[i].T-b\n",
    "            nowp=nowp+cur[i].shape[0]\n",
    "    Su=np.cov(u.T,rowvar=0)\n",
    "    Sw=np.cov(ep.T,rowvar=0)\n",
    "    oldSw=Sw\n",
    "    SuFG={}\n",
    "    SwG={}\n",
    "    for l in range(500):\n",
    "        F=np.linalg.pinv(Sw)\n",
    "        u=np.zeros([n,nc])\n",
    "        ep=np.zeros([n,withinCount])\n",
    "        nowp=0\n",
    "        for g in range(1000):\n",
    "            if numberBuff[g]==1:\n",
    "                #G = −(mS μ + S ε )−1*Su*Sw−1\n",
    "                G=-np.dot(np.dot(np.linalg.pinv(g*Su+Sw),Su),F)\n",
    "                #Su*(F+g*G) for u\n",
    "                SuFG[g]=np.dot(Su,(F+g*G))\n",
    "                #Sw*G for e\n",
    "                SwG[g]=np.dot(Sw,G)\n",
    "        for i in range(nc):\n",
    "            nnc=cur[i].shape[0]\n",
    "            #formula 7 in suppl_760\n",
    "            u[:,i]=np.sum(np.dot(SuFG[nnc],cur[i].T),1).ravel()     \n",
    "            #formula 8 in suppl_760\n",
    "            ep[:,nowp:nowp+cur[i].shape[0]]=cur[i].T+np.sum(np.dot(SwG[nnc],cur[i].T),1).reshape(n,1)\n",
    "            nowp=nowp+nnc\n",
    "        Su=np.cov(u.T,rowvar=0)\n",
    "        Sw=np.cov(ep.T,rowvar=0)\n",
    "        print(l,np.linalg.norm(Sw-oldSw)/np.linalg.norm(Sw))\n",
    "### Future work: need to consider below\n",
    "#         if np.linalg.norm(Sw-oldSw)/np.linalg.norm(Sw)<1e-6:\n",
    "#             break;\n",
    "        oldSw=Sw\n",
    "    F=np.linalg.pinv(Sw)\n",
    "    G=-np.dot(np.dot(np.linalg.pinv(2*Su+Sw),Su),F)\n",
    "    A=np.linalg.pinv(Su+Sw)-(F+G)\n",
    "    return A,G\n",
    "\n",
    "#ratio of similar,the threshold we always choose in (-1,-2)\n",
    "def jbverify(A,G,x1,x2):\n",
    "#     x1.shape=(-1,1)\n",
    "#     x2.shape=(-1,1)\n",
    "    ratio=np.dot(np.dot(np.transpose(x1),A),x1)+np.dot(np.dot(np.transpose(x2),A),x2)-2*np.dot(np.dot(np.transpose(x1),G),x2)\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.0541306  -1.5055318  -2.897702   -5.793125    0.2771138  -4.4020348\n",
      "  7.282463   -1.5974728  -5.74746     1.0986913   0.833211   -2.4517314\n",
      " -0.10165278  0.4647987  -2.054618   -1.8822994   1.4176805   0.09736018\n",
      " -0.8606803  -0.11187399]\n",
      "[[159]]\n"
     ]
    }
   ],
   "source": [
    "###   load PCA model and train/label dataset \n",
    "###\n",
    "\n",
    "\n",
    "import torch\n",
    "import time\n",
    "from sklearn import decomposition\n",
    "\n",
    "\n",
    "feature_extract_tensor_file = '../checkpoints/feature_extract_full.pth'\n",
    "feature_extract_after_PCA_tensor_file = '../checkpoints/feature_extract_after_PCA_full.pth'\n",
    "feature_extract_without_PCA_tensor_file = '../checkpoints/feature_extract_without_PCA_full.pth'\n",
    "jointBayesianModel_file = '../checkpoints/jointBayesianModel.pth'\n",
    "\n",
    "\n",
    "PCA = True\n",
    "\n",
    "if PCA == True:\n",
    "    featureAfterPCAList = torch.load(feature_extract_after_PCA_tensor_file)\n",
    "    print(featureAfterPCAList[\"features\"][0])\n",
    "    print(featureAfterPCAList[\"labels\"][0])\n",
    "    train_feat = featureAfterPCAList[\"features\"]\n",
    "    train_label = featureAfterPCAList[\"labels\"]\n",
    "    pca_model = featureAfterPCAList[\"PCAfit\"]\n",
    "else:\n",
    "    featureWithoutPCAList = torch.load(feature_extract_without_PCA_tensor_file)\n",
    "    print(featureWithoutPCAList[\"features\"][0])\n",
    "    print(featureWithoutPCAList[\"labels\"][0]) \n",
    "    train_feat = featureWithoutPCAList[\"features\"]\n",
    "    train_label = featureWithoutPCAList[\"labels\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes.size: 431\n",
      "index: [159 395 339 ...  38 427 312]\n",
      "feature shape (16016, 20), dim of feature 20, label shape (16016,), unique labels 431\n",
      "0 0.0004459704573004969\n",
      "1 4.441752109732755e-05\n",
      "2 2.8616810576885364e-06\n",
      "3 1.9854970317244426e-07\n",
      "4 1.4382000173598067e-08\n",
      "5 1.0640421804675028e-09\n",
      "6 7.956487981108916e-11\n",
      "7 5.982788037735494e-12\n",
      "8 4.5125428559680874e-13\n",
      "9 3.407310323570328e-14\n",
      "10 2.567088906271378e-15\n",
      "11 2.642893848727321e-16\n",
      "12 1.935861720585969e-16\n",
      "13 2.156448922050628e-16\n",
      "14 2.7947010976472984e-16\n",
      "15 2.1703406213831347e-16\n",
      "16 2.154123651203211e-16\n",
      "17 2.3338132928548964e-16\n",
      "18 2.427605402528534e-16\n",
      "19 1.881728267523618e-16\n",
      "20 2.4501361724281054e-16\n",
      "21 2.3147141378658607e-16\n",
      "22 1.8434169652300232e-16\n",
      "23 1.4951466688828406e-16\n",
      "24 1.9585240582561958e-16\n",
      "25 2.0593561608539439e-16\n",
      "26 1.8173082756734665e-16\n",
      "27 1.6724810945807867e-16\n",
      "28 2.3261258063327483e-16\n",
      "29 2.361878981861874e-16\n",
      "30 3.4109435701357026e-16\n",
      "31 2.091580036116669e-16\n",
      "32 2.0717882782993379e-16\n",
      "33 2.25995309741949e-16\n",
      "34 2.2136081329977915e-16\n",
      "35 2.712124507397002e-16\n",
      "36 1.981814608382247e-16\n",
      "37 1.7747643352922323e-16\n",
      "38 1.8537665425195333e-16\n",
      "39 2.109634861958832e-16\n",
      "40 2.214083718374847e-16\n",
      "41 1.79336040004732e-16\n",
      "42 2.4731716224492287e-16\n",
      "43 2.2884230959952403e-16\n",
      "44 2.8156692556473055e-16\n",
      "45 2.8151531369890005e-16\n",
      "46 2.1168263387422263e-16\n",
      "47 3.011787205633915e-16\n",
      "48 2.562285772245039e-16\n",
      "49 1.9054298405376572e-16\n",
      "50 2.1312483650954174e-16\n",
      "51 2.1363784444129848e-16\n",
      "52 1.9744221244902344e-16\n",
      "53 1.778666175101356e-16\n",
      "54 1.8352951788436043e-16\n",
      "55 2.404899939494074e-16\n",
      "56 2.864425016540022e-16\n",
      "57 2.481539204104617e-16\n",
      "58 1.5789257976198648e-16\n",
      "59 1.4148810834984967e-16\n",
      "60 2.134214879636952e-16\n",
      "61 1.994518042658139e-16\n",
      "62 1.7648904989499128e-16\n",
      "63 1.8312901655623125e-16\n",
      "64 1.644401639824533e-16\n",
      "65 1.4627564637633763e-16\n",
      "66 1.6079764525014535e-16\n",
      "67 1.8922855717019898e-16\n",
      "68 2.5449662893750465e-16\n",
      "69 1.9651158916758381e-16\n",
      "70 1.2865415740779436e-16\n",
      "71 2.1604171236746066e-16\n",
      "72 1.8903306547721561e-16\n",
      "73 1.9311672177503088e-16\n",
      "74 1.8013755744381153e-16\n",
      "75 1.342829308764262e-16\n",
      "76 1.8354223656419397e-16\n",
      "77 2.294693086015664e-16\n",
      "78 1.6746410203636368e-16\n",
      "79 1.9482991859610102e-16\n",
      "80 1.7723673540627443e-16\n",
      "81 2.542018582584894e-16\n",
      "82 2.1818626461061836e-16\n",
      "83 2.0281509100289939e-16\n",
      "84 2.084891532689206e-16\n",
      "85 2.740075906926958e-16\n",
      "86 2.9043080052547156e-16\n",
      "87 1.7766925074914094e-16\n",
      "88 2.045206341318896e-16\n",
      "89 1.7115528669699631e-16\n",
      "90 1.709613186632946e-16\n",
      "91 1.8148596114432e-16\n",
      "92 1.9862520521505363e-16\n",
      "93 1.7273317240974107e-16\n",
      "94 2.714273465101848e-16\n",
      "95 2.2491122736798577e-16\n",
      "96 1.694116493694081e-16\n",
      "97 1.4122960405870565e-16\n",
      "98 1.9726980207902942e-16\n",
      "99 1.57525963319793e-16\n",
      "100 1.744513891770305e-16\n",
      "101 1.3797845274304108e-16\n",
      "102 2.7553049514181325e-16\n",
      "103 1.4794928283249735e-16\n",
      "104 3.111226147347182e-16\n",
      "105 2.5121269850004203e-16\n",
      "106 2.886544721673446e-16\n",
      "107 2.7250606362987545e-16\n",
      "108 1.7551067085526393e-16\n",
      "109 1.5555765023136717e-16\n",
      "110 1.8120090926931406e-16\n",
      "111 1.8958392086127193e-16\n",
      "112 3.0028788316226587e-16\n",
      "113 2.0950071552143232e-16\n",
      "114 1.4476045707671578e-16\n",
      "115 1.9157481830377192e-16\n",
      "116 1.7527014812339182e-16\n",
      "117 1.5609829880161877e-16\n",
      "118 1.3531289011613662e-16\n",
      "119 2.11480043263016e-16\n",
      "120 2.2350132390037123e-16\n",
      "121 1.9314946978208254e-16\n",
      "122 2.523218033148748e-16\n",
      "123 2.1236814295111127e-16\n",
      "124 1.7258962527659088e-16\n",
      "125 2.017063651806266e-16\n",
      "126 2.268654874189722e-16\n",
      "127 2.7197762448828493e-16\n",
      "128 2.642886071678288e-16\n",
      "129 1.887517381155429e-16\n",
      "130 2.387138102461943e-16\n",
      "131 2.009066149623889e-16\n",
      "132 2.305213314511459e-16\n",
      "133 2.447735568568636e-16\n",
      "134 1.5904368056199286e-16\n",
      "135 1.8491193150694396e-16\n",
      "136 2.322769453055635e-16\n",
      "137 2.19118541675911e-16\n",
      "138 2.0703052902434683e-16\n",
      "139 1.485225040680696e-16\n",
      "140 1.6389086612801368e-16\n",
      "141 1.9368311529670775e-16\n",
      "142 2.539589502003276e-16\n",
      "143 2.1516989812002298e-16\n",
      "144 1.6590201360405307e-16\n",
      "145 1.688625390092373e-16\n",
      "146 1.70375655324673e-16\n",
      "147 2.0805120161707658e-16\n",
      "148 2.2115609513971534e-16\n",
      "149 1.805528304104614e-16\n",
      "150 1.4322362258981726e-16\n",
      "151 1.7463725660846793e-16\n",
      "152 1.714920455112865e-16\n",
      "153 1.623547695042956e-16\n",
      "154 1.7559611037532295e-16\n",
      "155 1.5816895803600713e-16\n",
      "156 1.5685047738061642e-16\n",
      "157 1.3481367015806894e-16\n",
      "158 1.6600817253671417e-16\n",
      "159 2.0298218379050542e-16\n",
      "160 1.8873462546461934e-16\n",
      "161 2.8499401502375195e-16\n",
      "162 2.736878311390033e-16\n",
      "163 2.0407304016721389e-16\n",
      "164 2.348549782186837e-16\n",
      "165 2.009452243334154e-16\n",
      "166 1.7298148345638063e-16\n",
      "167 2.5085084912006133e-16\n",
      "168 2.9127639724591755e-16\n",
      "169 2.194954245374693e-16\n",
      "170 2.0557824883679141e-16\n",
      "171 2.137571515282348e-16\n",
      "172 1.65989122008031e-16\n",
      "173 1.9178242129620705e-16\n",
      "174 1.5456521041288698e-16\n",
      "175 1.6799388710300083e-16\n",
      "176 2.0183701693490963e-16\n",
      "177 1.783837177361239e-16\n",
      "178 2.2169000886675034e-16\n",
      "179 1.6059618169944562e-16\n",
      "180 1.9011140411675533e-16\n",
      "181 1.773119830128663e-16\n",
      "182 1.7011135513857456e-16\n",
      "183 2.857161587178066e-16\n",
      "184 2.7817939278209264e-16\n",
      "185 1.6054893003976782e-16\n",
      "186 1.6230491817761098e-16\n",
      "187 2.0456117381967022e-16\n",
      "188 2.1154731973795734e-16\n",
      "189 1.7828484145163277e-16\n",
      "190 1.8592545591079878e-16\n",
      "191 2.1226399141855065e-16\n",
      "192 2.654554457255693e-16\n",
      "193 1.9018921551136851e-16\n",
      "194 1.8089037571149936e-16\n",
      "195 2.2326940060719426e-16\n",
      "196 1.598990524550909e-16\n",
      "197 2.1419080136006043e-16\n",
      "198 1.7400693989579655e-16\n",
      "199 1.932306165188119e-16\n",
      "200 1.9132444124271863e-16\n",
      "201 1.5966623871554108e-16\n",
      "202 2.4066948028616395e-16\n",
      "203 1.9891103881538592e-16\n",
      "204 1.882870453722015e-16\n",
      "205 1.7857111572555606e-16\n",
      "206 1.8451634839359526e-16\n",
      "207 2.632131290329331e-16\n",
      "208 2.2239132800291156e-16\n",
      "209 1.3370830720405858e-16\n",
      "210 1.8671082751843e-16\n",
      "211 2.1012869443474612e-16\n",
      "212 1.941659523800747e-16\n",
      "213 2.0115138196883808e-16\n",
      "214 2.8942593309809535e-16\n",
      "215 2.463404908985202e-16\n",
      "216 1.6032978417181556e-16\n",
      "217 1.9548237724393212e-16\n",
      "218 1.815047319088172e-16\n",
      "219 1.8597145837055773e-16\n",
      "220 2.619096380104141e-16\n",
      "221 2.243265360173302e-16\n",
      "222 2.890179805243144e-16\n",
      "223 2.395139616222876e-16\n",
      "224 2.7761721899820174e-16\n",
      "225 2.3756274899424983e-16\n",
      "226 2.1050519908916408e-16\n",
      "227 1.7613177215947862e-16\n",
      "228 1.7607046688200524e-16\n",
      "229 2.0750962225447852e-16\n",
      "230 1.879362445734449e-16\n",
      "231 2.1553965055386021e-16\n",
      "232 1.8767415696648284e-16\n",
      "233 1.6032498584902355e-16\n",
      "234 2.1959760712559207e-16\n",
      "235 1.9353252762254488e-16\n",
      "236 1.9085477010720066e-16\n",
      "237 2.283922183942921e-16\n",
      "238 2.0716037069792573e-16\n",
      "239 2.1557813513973168e-16\n",
      "240 1.8758054572851606e-16\n",
      "241 1.7326830096017444e-16\n",
      "242 1.828439808553896e-16\n",
      "243 1.970029092748474e-16\n",
      "244 1.8936291816864967e-16\n",
      "245 2.6038489833240485e-16\n",
      "246 2.1649111415382977e-16\n",
      "247 2.1291572994916624e-16\n",
      "248 2.3437538105697206e-16\n",
      "249 1.4069882197172607e-16\n",
      "250 2.1539180530027776e-16\n",
      "251 1.9080014612399602e-16\n",
      "252 1.438481449172217e-16\n",
      "253 2.1234088607461502e-16\n",
      "254 1.482282941429278e-16\n",
      "255 2.683912163235117e-16\n",
      "256 2.8179098267129115e-16\n",
      "257 2.2726835220710117e-16\n",
      "258 1.9638639165283052e-16\n",
      "259 1.770550562704355e-16\n",
      "260 1.7135007617822736e-16\n",
      "261 1.9520604635354679e-16\n",
      "262 2.6265394382347916e-16\n",
      "263 2.2052857460446094e-16\n",
      "264 1.7319197463128885e-16\n",
      "265 2.1686982471832602e-16\n",
      "266 1.7306360343137512e-16\n",
      "267 1.6488893749255986e-16\n",
      "268 2.5819354696019817e-16\n",
      "269 2.5523333171042286e-16\n",
      "270 2.7596651618605776e-16\n",
      "271 2.0005119925553843e-16\n",
      "272 1.8958454037888663e-16\n",
      "273 2.0666005525474126e-16\n",
      "274 2.7632824746679873e-16\n",
      "275 2.3327239591843516e-16\n",
      "276 2.6355685041913374e-16\n",
      "277 2.8778950784184935e-16\n",
      "278 1.7922108515703423e-16\n",
      "279 2.6877678860426928e-16\n",
      "280 2.093803573901489e-16\n",
      "281 1.9633368057505483e-16\n",
      "282 1.8318582781760406e-16\n",
      "283 2.3119023968831284e-16\n",
      "284 2.162688754216481e-16\n",
      "285 2.353839530983025e-16\n",
      "286 1.9822419687177137e-16\n",
      "287 1.924988470830449e-16\n",
      "288 2.266216179813872e-16\n",
      "289 2.226760601135303e-16\n",
      "290 1.6647997056053591e-16\n",
      "291 1.4511352981141455e-16\n",
      "292 2.1164454042843018e-16\n",
      "293 1.8927355127014873e-16\n",
      "294 1.7221921179971438e-16\n",
      "295 1.4905267512493776e-16\n",
      "296 1.647889533577151e-16\n",
      "297 2.3393643775043505e-16\n",
      "298 2.870764486307567e-16\n",
      "299 2.313087477750254e-16\n",
      "300 2.4093030598097028e-16\n",
      "301 1.6781777389987323e-16\n",
      "302 2.24944789876761e-16\n",
      "303 2.93626782916858e-16\n",
      "304 1.4797926283170341e-16\n",
      "305 1.8468312427196471e-16\n",
      "306 2.0826012739427566e-16\n",
      "307 1.7375548095196173e-16\n",
      "308 1.928774502524412e-16\n",
      "309 2.0548029070041612e-16\n",
      "310 1.9168632051064333e-16\n",
      "311 2.3422839646266936e-16\n",
      "312 1.684515655505212e-16\n",
      "313 1.8873924214395628e-16\n",
      "314 1.8622942266216984e-16\n",
      "315 1.5565956483953352e-16\n",
      "316 2.0971397981624874e-16\n",
      "317 3.331176083572307e-16\n",
      "318 3.148960957609197e-16\n",
      "319 2.2010993625274953e-16\n",
      "320 2.427023184396402e-16\n",
      "321 1.7205446366713708e-16\n",
      "322 1.7070841361580153e-16\n",
      "323 2.5330362703991737e-16\n",
      "324 3.8881711805613013e-16\n",
      "325 3.009464524054518e-16\n",
      "326 2.2557685908246083e-16\n",
      "327 2.0029472469313405e-16\n",
      "328 2.48857415573308e-16\n",
      "329 2.7911298164525163e-16\n",
      "330 2.7934177419702997e-16\n",
      "331 2.1284391280904556e-16\n",
      "332 2.0549077913521754e-16\n",
      "333 2.3193823222969163e-16\n",
      "334 1.7982146470336043e-16\n",
      "335 1.9738893169492545e-16\n",
      "336 2.0450633063358455e-16\n",
      "337 1.9251651356711826e-16\n",
      "338 2.5808104983891806e-16\n",
      "339 2.6258545371594524e-16\n",
      "340 2.2177178124522587e-16\n",
      "341 2.265930596060061e-16\n",
      "342 1.7202138671729419e-16\n",
      "343 1.856235579487851e-16\n",
      "344 2.364294139500359e-16\n",
      "345 2.4569399598340034e-16\n",
      "346 1.870289981394358e-16\n",
      "347 1.7172166765012198e-16\n",
      "348 1.9280389151235737e-16\n",
      "349 2.1590336387078112e-16\n",
      "350 1.9858916477480118e-16\n",
      "351 3.1326254939401246e-16\n",
      "352 2.8074049128985474e-16\n",
      "353 1.8331214417621782e-16\n",
      "354 1.5907521058446444e-16\n",
      "355 2.0903468446575858e-16\n",
      "356 2.0924339654850167e-16\n",
      "357 2.1613360680958025e-16\n",
      "358 2.0597425215752365e-16\n",
      "359 1.8427037125387123e-16\n",
      "360 2.2783691471544454e-16\n",
      "361 1.9975040178107284e-16\n",
      "362 1.6255552117998844e-16\n",
      "363 2.7710249028282227e-16\n",
      "364 2.08298004563509e-16\n",
      "365 1.9667169807049865e-16\n",
      "366 1.7753611212676235e-16\n",
      "367 1.7409623759979063e-16\n",
      "368 2.3136977322554145e-16\n",
      "369 2.3687918602131663e-16\n",
      "370 2.032505431069041e-16\n",
      "371 2.1276452955707526e-16\n",
      "372 2.232623251284771e-16\n",
      "373 1.7115801441345114e-16\n",
      "374 1.8317840628165663e-16\n",
      "375 1.8945132848440866e-16\n",
      "376 2.0403187461406052e-16\n",
      "377 2.51402694306619e-16\n",
      "378 3.010626625252225e-16\n",
      "379 3.5576373479591937e-16\n",
      "380 2.2074564698076244e-16\n",
      "381 2.1603454967867134e-16\n",
      "382 2.6434530696666446e-16\n",
      "383 2.4319335175733445e-16\n",
      "384 2.2177957618710523e-16\n",
      "385 1.9531070614004877e-16\n",
      "386 1.7298771297524488e-16\n",
      "387 1.8969696092639083e-16\n",
      "388 2.0630676097222263e-16\n",
      "389 2.587125033290646e-16\n",
      "390 1.6031903353149205e-16\n",
      "391 2.2437681606258025e-16\n",
      "392 1.8839907514840486e-16\n",
      "393 1.7214120498475946e-16\n",
      "394 2.105293254325103e-16\n",
      "395 1.820417339722003e-16\n",
      "396 2.1519082708826374e-16\n",
      "397 2.1536845544361486e-16\n",
      "398 2.319646135515137e-16\n",
      "399 2.2482845825795987e-16\n",
      "400 2.0711115308928224e-16\n",
      "401 2.6140155871187877e-16\n",
      "402 2.8171176892275317e-16\n",
      "403 1.962702589921279e-16\n",
      "404 2.1270653515802256e-16\n",
      "405 1.9360977165998785e-16\n",
      "406 2.2337302147651073e-16\n",
      "407 1.690132649665783e-16\n",
      "408 1.846059823150636e-16\n",
      "409 1.3979534821118596e-16\n",
      "410 1.9306351342722643e-16\n",
      "411 1.8819802570079954e-16\n",
      "412 2.4896203598499893e-16\n",
      "413 2.2314835009039467e-16\n",
      "414 1.889900610851388e-16\n",
      "415 2.0508529505319216e-16\n",
      "416 2.2180823803371373e-16\n",
      "417 2.0779532357777248e-16\n",
      "418 2.881734599278294e-16\n",
      "419 3.039559996959962e-16\n",
      "420 1.9029881395541247e-16\n",
      "421 1.921725320789685e-16\n",
      "422 1.863289682629959e-16\n",
      "423 2.2029947291766297e-16\n",
      "424 2.40687938817025e-16\n",
      "425 2.1442300988943667e-16\n",
      "426 1.9861208120518245e-16\n",
      "427 1.711183081253813e-16\n",
      "428 1.6839537625713567e-16\n",
      "429 1.9001727060961463e-16\n",
      "430 1.555824698790124e-16\n",
      "431 1.8883980872454779e-16\n",
      "432 1.5351576529402384e-16\n",
      "433 1.8331196797961333e-16\n",
      "434 2.2805095440941667e-16\n",
      "435 2.5573010816258522e-16\n",
      "436 2.45254235820973e-16\n",
      "437 1.795199782127501e-16\n",
      "438 2.965449633222796e-16\n",
      "439 2.98252951917374e-16\n",
      "440 1.926300772540743e-16\n",
      "441 1.4778738111215453e-16\n",
      "442 1.7500168379779326e-16\n",
      "443 1.8958315807742805e-16\n",
      "444 2.52405241367742e-16\n",
      "445 2.0825775521616117e-16\n",
      "446 1.6014459659423865e-16\n",
      "447 2.121216391155765e-16\n",
      "448 2.084731678168081e-16\n",
      "449 1.8443283623868135e-16\n",
      "450 1.8769978657234795e-16\n",
      "451 1.4851624183258406e-16\n",
      "452 2.3775564694359174e-16\n",
      "453 3.597100835034873e-16\n",
      "454 2.635160686632752e-16\n",
      "455 2.03564891717912e-16\n",
      "456 2.280801412921852e-16\n",
      "457 2.2681511177625616e-16\n",
      "458 2.354612784447852e-16\n",
      "459 2.409380599712615e-16\n",
      "460 2.0457588613143272e-16\n",
      "461 2.488541678766892e-16\n",
      "462 1.8646552885279789e-16\n",
      "463 2.561099890730544e-16\n",
      "464 1.9789283745773254e-16\n",
      "465 1.9766566098513515e-16\n",
      "466 1.7690495780211112e-16\n",
      "467 2.0545403511476174e-16\n",
      "468 2.0351258269567451e-16\n",
      "469 2.1269013499260673e-16\n",
      "470 2.004114408826132e-16\n",
      "471 1.9642507108741544e-16\n",
      "472 2.048659547250889e-16\n",
      "473 1.7101652324348383e-16\n",
      "474 1.713949325742187e-16\n",
      "475 1.9178082517836732e-16\n",
      "476 2.0267294386023307e-16\n",
      "477 1.7184652619785085e-16\n",
      "478 2.3394980792686715e-16\n",
      "479 2.692615250432612e-16\n",
      "480 2.9434042852417223e-16\n",
      "481 2.0807045113818108e-16\n",
      "482 1.8604224195375862e-16\n",
      "483 1.8996639755826624e-16\n",
      "484 2.7637817727652966e-16\n",
      "485 1.7414326991395836e-16\n",
      "486 1.8139808766448472e-16\n",
      "487 2.5025436373957474e-16\n",
      "488 2.321931313856133e-16\n",
      "489 2.157421581931422e-16\n",
      "490 1.8926733030945525e-16\n",
      "491 1.7251342418964497e-16\n",
      "492 1.571270909002805e-16\n",
      "493 1.7867961157841882e-16\n",
      "494 1.9275872752607674e-16\n",
      "495 2.1467646614205217e-16\n",
      "496 1.7295260747023512e-16\n",
      "497 2.0935776062315308e-16\n",
      "498 1.9399676784308568e-16\n",
      "499 1.9521642122635313e-16\n",
      "Finished in 19.037014 seconds\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "#   training joint bayesian and save the model\n",
    "###################################\n",
    "\n",
    "import torch\n",
    "import time\n",
    "\n",
    "print('Training...')\n",
    "t1 = time.time()\n",
    "A, G = jbtrain(train_feat, train_label)\n",
    "t2 = time.time()\n",
    "print('Finished in %f seconds' % (t2-t1))\n",
    "\n",
    "jointBayesianModel = {\n",
    "    \"A\": A,\n",
    "    \"G\": G\n",
    "}\n",
    "\n",
    "torch.save(jointBayesianModel, jointBayesianModel_file)\n",
    "print(\"done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Shape (20, 20) len 20 ,G shape (20, 20) len 20\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "#   load joint bayesian model\n",
    "###################################\n",
    "\n",
    "import torch\n",
    "import time\n",
    "feature_extract_after_PCA_tensor_file = '../checkpoints/feature_extract_after_PCA_full.pth'\n",
    "jointBayesianModel_file = '../checkpoints/jointBayesianModel.pth'\n",
    "\n",
    "jointBayesianModel = torch.load(jointBayesianModel_file)\n",
    "A = jointBayesianModel[\"A\"]\n",
    "G = jointBayesianModel[\"G\"]\n",
    "print('A Shape {} len {} ,G shape {} len {}'.format(A.shape, len(A), G.shape, len(G)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "total GPU: 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import csv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import glob\n",
    "import os.path as osp\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils import data as D\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "print(\"total GPU: %d\" %(torch.cuda.device_count()))\n",
    "\n",
    "class DefaultConfig(object):\n",
    "    env = 'default' # visdom 环境\n",
    "    path = '../data/compcars/data/cropped_image/'   #../data/compcars/data/image\n",
    "    labelPath = '../data/compcars/data/label/'\n",
    "    miscPath = '../data/compcars/data/misc/'\n",
    "    modleNameFile = '../data/compcars/data/misc/modle_names.csv'\n",
    "    makeNameFile = '../data/compcars/data/misc/make_names.csv'\n",
    "    trainFilename = '../data/compcars/data/train_test_split/classification/train.txt'\n",
    "    testFilename = '../data/compcars/data/train_test_split/classification/test.txt'\n",
    "    verificationEasyFilename = '../data/compcars/data/train_test_split/verification/verification_pairs_easy.txt'\n",
    "    verificationMediumFilename = '../data/compcars/data/train_test_split/verification/verification_pairs_medium.txt'\n",
    "    verificationHardFilename = '../data/compcars/data/train_test_split/verification/verification_pairs_hard.txt'\n",
    "    log_dir = '../log/'\n",
    "    num_workers = 8\n",
    "    num_epoches = 100\n",
    "    num_classes = 431\n",
    "    lr = 0.1\n",
    "    lr_decay = 0.95\n",
    "    max_epoch = 200000\n",
    "    weight_decay = 1e-4\n",
    "    load_model_path = '../checkpoints/train.pth'\n",
    "    previous_loss = 1e100\n",
    "    modle_csv_file = 'modle_names.csv'\n",
    "    jointBayesianThreshold = -100\n",
    "\n",
    "opt = DefaultConfig()\n",
    "logger = SummaryWriter(opt.log_dir, flush_secs=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "# load previous save model\n",
    "###############################\n",
    "\n",
    "# Load the model \n",
    "continue_model_inception3 = torchvision.models.inception_v3(pretrained=None)\n",
    "net = continue_model_inception3\n",
    "\n",
    "# # # modify output classes\n",
    "num_ftrs = net.fc.in_features\n",
    "net.fc = torch.nn.Linear(num_ftrs, opt.num_classes)    #num_ftrs = 2048\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion.cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "checkpoint = torch.load(opt.load_model_path)\n",
    "net.load_state_dict(checkpoint['model_state_dict'])  \n",
    "\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    net = torch.nn.DataParallel(net)\n",
    "net.cuda()\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************** image 1000 *******************\n",
      "1000 --- Feature extraction in 0.202955 s, prediction: 0.000050 s\n",
      "result: -1.661495(1)\n",
      "***************** image 2000 *******************\n",
      "2000 --- Feature extraction in 0.208756 s, prediction: 0.000059 s\n",
      "result: -8.930168(1)\n",
      "***************** image 3000 *******************\n",
      "3000 --- Feature extraction in 0.231494 s, prediction: 0.000058 s\n",
      "result: -16.310215(1)\n",
      "***************** image 4000 *******************\n",
      "4000 --- Feature extraction in 0.251695 s, prediction: 0.000059 s\n",
      "result: 2.756601(1)\n",
      "***************** image 5000 *******************\n",
      "5000 --- Feature extraction in 0.178049 s, prediction: 0.000059 s\n",
      "result: -5.391550(1)\n",
      "***************** image 6000 *******************\n",
      "6000 --- Feature extraction in 0.112487 s, prediction: 0.000051 s\n",
      "result: -6.467470(1)\n",
      "***************** image 7000 *******************\n",
      "7000 --- Feature extraction in 0.211112 s, prediction: 0.000048 s\n",
      "result: 3.033164(1)\n",
      "***************** image 8000 *******************\n",
      "8000 --- Feature extraction in 0.110181 s, prediction: 0.000057 s\n",
      "result: -5.689845(1)\n",
      "***************** image 9000 *******************\n",
      "9000 --- Feature extraction in 0.200884 s, prediction: 0.000051 s\n",
      "result: -0.444473(1)\n",
      "***************** image 10000 *******************\n",
      "10000 --- Feature extraction in 0.106157 s, prediction: 0.000051 s\n",
      "result: -8.529699(1)\n",
      "***************** image 11000 *******************\n",
      "11000 --- Feature extraction in 0.107220 s, prediction: 0.000054 s\n",
      "result: -25.739710(0)\n",
      "***************** image 12000 *******************\n",
      "12000 --- Feature extraction in 0.103571 s, prediction: 0.000058 s\n",
      "result: -48.262097(0)\n",
      "***************** image 13000 *******************\n",
      "13000 --- Feature extraction in 0.107737 s, prediction: 0.000070 s\n",
      "result: -31.449153(0)\n",
      "***************** image 14000 *******************\n",
      "14000 --- Feature extraction in 0.101994 s, prediction: 0.000057 s\n",
      "result: -68.751072(0)\n",
      "***************** image 15000 *******************\n",
      "15000 --- Feature extraction in 0.180014 s, prediction: 0.000058 s\n",
      "result: -37.619093(0)\n",
      "***************** image 16000 *******************\n",
      "16000 --- Feature extraction in 0.102981 s, prediction: 0.000046 s\n",
      "result: -11.696639(0)\n",
      "***************** image 17000 *******************\n",
      "17000 --- Feature extraction in 0.107942 s, prediction: 0.000070 s\n",
      "result: -29.155742(0)\n",
      "***************** image 18000 *******************\n",
      "18000 --- Feature extraction in 0.106797 s, prediction: 0.000066 s\n",
      "result: -49.197942(0)\n",
      "***************** image 19000 *******************\n",
      "19000 --- Feature extraction in 0.104189 s, prediction: 0.000044 s\n",
      "result: -31.696698(0)\n",
      "***************** image 20000 *******************\n",
      "20000 --- Feature extraction in 0.107213 s, prediction: 0.000066 s\n",
      "result: -32.308068(0)\n",
      "pos mean, std, mean, max : -3.908126, 11.807555, -79.430037, 44.381689\n",
      "neg mean, std, mean, max : -37.012171, 21.332399, -128.554675, 21.060877\n",
      "hit rate: 0.502450\n"
     ]
    }
   ],
   "source": [
    "###########################################\n",
    "# test with CNN model + Joint Bayesian\n",
    "###########################################\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "   mean=[0.485, 0.456, 0.406],\n",
    "   std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "def verificationTransform(imagefile):\n",
    "    veri_transform = transforms.Compose([\n",
    "                transforms.Scale(299),\n",
    "                transforms.CenterCrop(299), \n",
    "                transforms.ToTensor(),\n",
    "                normalize\n",
    "        ]) \n",
    "    \n",
    "    imagefile = os.path.join(opt.path, imagefile)\n",
    "    image = Image.open(imagefile)\n",
    "    image = veri_transform(image)\n",
    "\n",
    "    return image.unsqueeze_(0)\n",
    "\n",
    "\n",
    "level = 'easy'  # or 'hard' or 'medium'\n",
    "DATA_DIR = '../data/compcars/data/'\n",
    "test_file = os.path.join(DATA_DIR, 'train_test_split/verification/verification_pairs_%s.txt' % level)\n",
    "test_list = list(map(lambda s: s.strip().split(' '), open(test_file).readlines()))\n",
    "N = len(test_list)\n",
    "preds = np.zeros((N,))\n",
    "gts = np.array(map(lambda t: int(t[-1]), test_list))\n",
    "hit_num = 0\n",
    "\n",
    "\n",
    "inFCVeri = []\n",
    "outFCVeri = []\n",
    "def hookVerification(module, i, o):\n",
    "    inFCVeri.append(i)\n",
    "    outFCVeri.append(o)\n",
    "    \n",
    "    \n",
    "model = net  \n",
    "model.eval()\n",
    "model.module.fc.register_forward_hook(hookVerification)\n",
    "featureList = []\n",
    "currentFeature = []\n",
    "\n",
    "for i, test_data in enumerate(test_list):\n",
    "    gt = int(test_data[-1])\n",
    "    t1 = time.time()\n",
    "    \n",
    "    # 1/ fetch image file\n",
    "    imgfile1, imgfile2 = test_data[0], test_data[1]\n",
    "    img1 = verificationTransform(imgfile1)\n",
    "    img2 = verificationTransform(imgfile2)\n",
    "    img1, img2 = Variable(img1.cuda()), Variable(img2.cuda())\n",
    "\n",
    "    # 2/ fetch feature matrixs\n",
    "    x1 = model(img1)\n",
    "    x1_in2048 = inFCVeri[0][0][0].data.cpu().numpy()\n",
    "    inFCVeri = []\n",
    "    outFCVeri = []\n",
    "    \n",
    "    x2 = model(img2)\n",
    "    x2_in2048 = inFCVeri[0][0][0].data.cpu().numpy()\n",
    "    inFCVeri = []\n",
    "    outFCVeri = []\n",
    "    # x1 shape torch.Size([2048]), x2 shape torch.Size([2048])\n",
    "     \n",
    "    # 3/ PCA to 20 \n",
    "    xx1 = pca_model.transform(np.asmatrix(x1_in2048))\n",
    "    xx2 = pca_model.transform(np.asmatrix(x2_in2048))\n",
    "    #pca_model.components_.reshape(2048, 20).shape\n",
    "    # shapes (1,40960) and (20,20) not aligned: 40960 (dim 1) != 20 (dim 0)    \n",
    "\n",
    "    # 4/ JB verification    \n",
    "    t2 = time.time()\n",
    "    preds[i] = jbverify(A, G, xx1, xx2)    \n",
    "    #ratio=np.dot(np.dot(np.transpose(x1),A),x1)+np.dot(np.dot(np.transpose(x2),A),x2)-2*np.dot(np.dot(np.transpose(x1),G),x2)\n",
    "    # A (20, 20), G(20, 20)\n",
    "    \n",
    "    t3 = time.time() \n",
    "    if (preds[i]>opt.jointBayesianThreshold and gt==1) or(preds[i]<opt.jointBayesianThreshold and gt==0):\n",
    "        hit_num = hit_num+1\n",
    "\n",
    "    if (i+1)%1000==0:\n",
    "        print('***************** image %d *******************' % (i+1))\n",
    "        print('%d --- Feature extraction in %f s, prediction: %f s\\nresult: %f(%d)' % (i+1, t2-t1, t3-t2, preds[i], gt))\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "test_list2 = list(map(lambda s: s.strip().split(' '), open(test_file).readlines()))\n",
    "gts = np.asarray(list(map(lambda t: int(t[-1]), test_list2)))\n",
    "  \n",
    "print('pos mean, std, mean, max : %f, %f, %f, %f' % (preds[gts==1].mean(), preds[gts==1].std(), preds[gts==1].min(), preds[gts==1].max()))\n",
    "print('neg mean, std, mean, max : %f, %f, %f, %f' % (preds[gts==0].mean(), preds[gts==0].std(), preds[gts==0].min(), preds[gts==0].max()))\n",
    "print('hit rate: %f' % (hit_num*1.0/N))\n",
    "  \n",
    "    \n",
    "\n",
    "# Dec 2 2018\n",
    "# preds 1 mean -3.9081270492731113 std 11.807556093672183 min -79.43003772026832 max 44.3816863572722\n",
    "# preds 0 mean -37.01217310158124 std 21.332399250284972 min -128.55467633653916 max 21.060876005203426\n",
    "\n",
    "# Dec 3 2018\n",
    "# pos mean, std, mean, max : -3.908126, 11.807555, -79.430037, 44.381689\n",
    "# neg mean, std, mean, max : -37.012171, 21.332399, -128.554675, 21.060877\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
