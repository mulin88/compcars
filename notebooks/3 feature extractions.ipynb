{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16016\n",
      "total train feature size: 431\n",
      "12\n",
      "total compcars dataset feature size: 2004\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "# load previous save model\n",
    "###############################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import csv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import glob\n",
    "import os.path as osp\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils import data as D\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "class DefaultConfig(object):\n",
    "    path = '../data/compcars/data/cropped_image/'   #../data/compcars/data/image\n",
    "    labelPath = '../data/compcars/data/label/'\n",
    "    miscPath = '../data/compcars/data/misc/'\n",
    "    modleNameFile = '../data/compcars/data/misc/modle_names.csv'\n",
    "    makeNameFile = '../data/compcars/data/misc/make_names.csv'\n",
    "    trainFilename = '../data/compcars/data/train_test_split/classification/train.txt'\n",
    "    testFilename = '../data/compcars/data/train_test_split/classification/test.txt'\n",
    "    verificationFilename = '../data/compcars/data/train_test_split/verification/verification_train.txt'\n",
    "    log_dir = '../log/'\n",
    "    num_workers = 8\n",
    "    num_epoches = 100\n",
    "    lr = 0.1\n",
    "    lr_decay = 0.95\n",
    "    max_epoch = 200000\n",
    "    weight_decay = 1e-4\n",
    "    load_model_path = '../checkpoints/train.pth'\n",
    "    previous_loss = 1e100\n",
    "    modle_csv_file = 'modle_names.csv'\n",
    "\n",
    "opt = DefaultConfig()\n",
    "\n",
    "# DataSet and DataLoader\n",
    "normalize = transforms.Normalize(\n",
    "   mean=[0.485, 0.456, 0.406],\n",
    "   std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "\n",
    "class CompcarsDS(D.Dataset):\n",
    "    \"\"\"\n",
    "    A customized data loader.\n",
    "    \"\"\"\n",
    "    def __init__(self, root, mode='train'):\n",
    "        \"\"\" Intialize the dataset\n",
    "        \"\"\"\n",
    "        self.filenames = []\n",
    "        self.root = root\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.Scale(299),\n",
    "            transforms.CenterCrop(299), \n",
    "            transforms.ToTensor(),\n",
    "            normalize\n",
    "        ])\n",
    "                    \n",
    "        # below for train dataset selected by the paper\n",
    "        with open(opt.trainFilename, newline='\\n') as trainfile:\n",
    "            for line in trainfile:\n",
    "                self.filenames.append(opt.path + line.replace(\"\\n\",\"\"))\n",
    "        \n",
    "        self.len = len(self.filenames)\n",
    "        \n",
    "    # You must override __getitem__ and __len__\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Get a sample from the dataset\n",
    "        \"\"\"\n",
    "        image = Image.open(self.filenames[index])\n",
    "        labelStr = self.filenames[index].split(\"/\")[6]\n",
    "        label = paperTrainFeatureList.index(labelStr)\n",
    "        return self.transform(image), label\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Total number of samples in the dataset\n",
    "        \"\"\"\n",
    "        return self.len\n",
    "\n",
    " \n",
    "\"\"\"\n",
    "Verification dataset\n",
    "\"\"\"\n",
    "verificationCars = CompcarsDS(opt.path)\n",
    "print(verificationCars.len)   \n",
    "    \n",
    "####   verification dataset Loader\n",
    "##########################################################\n",
    "verificationloader = D.DataLoader(verificationCars, batch_size=1, shuffle=True, num_workers=8, pin_memory=True)\n",
    "\n",
    "    \n",
    "\n",
    "# Load the model \n",
    "continue_model_inception3 = torchvision.models.inception_v3(pretrained=None)\n",
    "net = continue_model_inception3\n",
    "\n",
    "# # # modify output classes\n",
    "num_ftrs = net.fc.in_features\n",
    "num_classes = 431\n",
    "net.fc = torch.nn.Linear(num_ftrs, num_classes)    #num_ftrs = 2048\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "criterion.cuda()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "checkpoint = torch.load(opt.load_model_path)\n",
    "net.load_state_dict(checkpoint['model_state_dict'])  \n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    net = torch.nn.DataParallel(net)\n",
    "net.cuda()\n",
    "\n",
    "\n",
    "##############################\n",
    "# calculate the features size from paper's training dataset\n",
    "##############################\n",
    "paperTrainFeatureSet = set()\n",
    "with open(opt.trainFilename, newline='\\n') as trainfile:\n",
    "            for line in trainfile:\n",
    "                feature = line.split('/')[1]\n",
    "                paperTrainFeatureSet.add(feature)\n",
    "print('total train feature size: %s' %(len(paperTrainFeatureSet)))\n",
    "num_classes = len(paperTrainFeatureSet)\n",
    "paperTrainFeatureList = sorted(paperTrainFeatureSet)\n",
    "featureIndex = paperTrainFeatureList.index('104')\n",
    "print(featureIndex)\n",
    "\n",
    "compcarsFeatures = {}\n",
    "modle_csv = os.path.join(opt.miscPath, opt.modle_csv_file)\n",
    "with open(modle_csv, newline='\\n') as modlefile:\n",
    "    for line in modlefile:\n",
    "        items = line.split(',')\n",
    "        key, values = items[0], items[1]\n",
    "        compcarsFeatures[key] = values\n",
    "\n",
    "print('total compcars dataset feature size:', len(compcarsFeatures))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureList = []\n",
    "inFC =  torch.zeros(1, 2048).cuda()\n",
    "outFC = torch.zeros(1, 431).cuda()\n",
    "\n",
    "inFC1 = []\n",
    "outFC1 = []\n",
    "\n",
    "\n",
    "def hook2(module, i, o):\n",
    "    inFC1.append(i)\n",
    "    outFC1.append(o)\n",
    "    \n",
    "model = net  \n",
    "dataloders = verificationloader\n",
    "model.eval()\n",
    "model.module.fc.register_forward_hook(hook2)\n",
    "featureList = []\n",
    "currentFeature = []\n",
    "\n",
    "for i, (inputs, labels) in enumerate(dataloders):\n",
    "    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "    outputs = model(inputs)\n",
    "    _, preds = torch.max(outputs.data, 1)\n",
    "    i += 1\n",
    "    \n",
    "    in2048 = inFC1[0][0][0].data\n",
    "    out431 = outFC1[0][0].data\n",
    "    currentFeature = [in2048, out431, labels.item(), preds.item()]\n",
    "    featureList.append(currentFeature)\n",
    "\n",
    "    currentFeature = []\n",
    "    inFC1 = []\n",
    "    outFC1 = []\n",
    "  \n",
    "    \n",
    "print(len(featureList))\n",
    "feature_extract_tensor_file = '../checkpoints/feature_extract_full.pth'\n",
    "torch.save(featureList, feature_extract_tensor_file)\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
